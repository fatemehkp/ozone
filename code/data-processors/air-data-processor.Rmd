---
title: "Air Quality Data - Ozone"
author: "Fatemeh Kazemi"
date: "01-15-2021"
output:
  html_document:
    df_print: paged
---

#### To Do:
#      Merge it with CMS
###############################################################################

### This program:
  (1) Downloads and cleans hourly and 8hour ozone data measured by EPA
      i. https://aqs.epa.gov/aqsweb/airdata/download_files.html
  (2) Choose a subset of monitors on the basis of data availability
      i. 18hours - 21days - 5 warm-month- 4years
  (3) Constructs three measures of ozone including:
      i. daily 1-h max
      ii. daily 24-h avg
      iii. daily 8-h max
  (4) Calculates warm-season average of each ozone measure
  (5) Uses cross-walk files between Sites and Zipcodes to assign the measurements
      from Sites to the Zipcodes in their x-mile bufferzone
  (5) Merge it with CMS data (on NEU Cluster) to find the Sites which have
      population living in their x-mile bufferzone
      
### Note:
  1. In data merged with CMS, bufferzone is 6-mile unless specified

```{r load packages}
library(tidyverse)
library(here)
library(lubridate)
```

```{r Call Functions}
source(here('code','data-processors','epa-air-data-download-function.R'))
source(here('code','data-processors','air-data-processor-function.R'))
```

```{r load data}
dirUSSpatial <- 
  'C:\\Users\\fkazem01\\Box\\Projects\\USA Spatial\\data\\processed\\'
dirPMC <- 
  'C:\\Users\\fkazem01\\Box\\Projects\\PM Components\\data\\processed\\'
load(paste0(dirUSSpatial,'state-region.RDa'))
load(paste0(dirUSSpatial,'site-zip.RDa'))
load(paste0(dirPMC,'aqs-sites.RDa'))
```

```{r EPA AQS Data Download - hourly data}
#Using EPA.AQS.download Function
dt.ozone.h.raw <- EPA.AQS.download.h (period = "hourly", Index = c(44201),
                        start = 2000, end = 2008)
save(dt.ozone.h.raw, file = here('data', 'raw', 'ozone-hour-raw.RDa'))
#Monitor.ID: Site.ID-POC

monitor.ozone <- dt.ozone.h.raw %>% distinct(Monitor.ID) #1653
site.ozone <- dt.ozone.h.raw %>% distinct(Site.ID)#1632
```

```{r EPA AQS Data Download - 8hour data}
#Using EPA.AQS.download Function
dt.ozone.8h.raw <- EPA.AQS.download.8h (period = "8hour", Index = c(44201),
                        start = 2000, end = 2008)
save(dt.ozone.8h.raw, file = here('data', 'raw', 'ozone-8hour-raw.RDa'))
#Monitor.ID: Site.ID-POC

monitor.ozone <- dt.ozone.8h.raw %>% distinct(Monitor.ID)#1654
site.ozone <- dt.ozone.8h.raw %>% distinct(Site.ID) #1633
```

```{r Air quality data Process}
# Find sites with at least 18hour, 4day, 9month and 4year
# Using Air.Hourly.Process function
dt.ozone.h.sel <- Air.Hourly.Process(dt = dt.ozone.h.raw, m1 = 4, m2 = 9,
                                  h = 18, d = 21, m = 5, y = 4)
save(dt.ozone.h.sel, 
     file = here('data', 'processed', 'ozone-hour-selected.RDa'))

#Calculate daily max and avg for hourly data
dt.ozone.h <- dt.ozone.h.sel %>% 
  group_by(Monitor.ID, Site.ID, POC, Date) %>% 
  summarise(maxh = max(Sample.Measurement),
            avgh = mean(Sample.Measurement))

# We do not need to find sites again
# Calculate daily max for 8-hour average data ...
# ... and merge it with qualified hourly data
dt.ozone.8h <- dt.ozone.8h.raw %>% 
  group_by(Monitor.ID, Site.ID, POC, Date) %>% 
  summarise(max8h = max(Mean.Including.All.Data))

dt.ozone.day.sel <- left_join(dt.ozone.h, dt.ozone.8h)

# POC: Parameter Occurrence Code ...
# ... more than one instrument measured ozone at one site
# Pick the POC(instrument) with larger number of measurements
site.POC.larger <- dt.ozone.day.sel %>% 
  group_by(Site.ID, POC) %>% 
  summarise(n = n()) %>% 
  group_by(Site.ID) %>% 
  filter(n == max (n)) %>% 
  select(Site.ID, POC)

dt.ozone.day.sel <- merge(dt.ozone.day.sel, site.POC.larger) %>% 
   arrange(Site.ID, Date)

monitor.ozone <- dt.ozone.day.sel %>% distinct(Monitor.ID) #1654 > 1271
site.ozone <- dt.ozone.day.sel %>% distinct(Site.ID) #1632 > 1271

dt.ozone.day.sel$POC <- dt.ozone.day.sel$Monitor.ID <- NULL
save(dt.ozone.day.sel, 
     file = here('data', 'processed', 'ozone-day-selected.RDa'))
```

```{r Caluculating warm-season avg for each year}
dt.ozone.warm <- dt.ozone.day.sel %>% 
  mutate(Year = year(Date)) %>% 
  group_by(Site.ID, Year) %>% 
  summarise(O3.maxh = mean(maxh, na.rm = T),
            O3.avgh = mean(avgh,  na.rm = T),
            O3.max8h = mean (max8h, na.rm = T))

save(dt.ozone.warm, file = here('data', 'processed', 'ozone-warm.RDa'))

dt.site.ozone.warm <- dt.ozone.warm %>% distinct(Site.ID) %>%  #1271
  merge(dt.aqs.sites)
save(dt.site.ozone.warm, 
     file = here('data', 'processed', 'site-ozone-warm.RDa'))

dt.site.ozone.warm %>% 
  group_by(Location.Setting) %>% 
  summarise(n = n())
#Location.Setting  n
#                  8			
#RURAL	           564			
#SUBURBAN	         493			
#URBAN AND CENTER CITY	           206	

dt.ozone.warm %>% 
  distinct(Site.ID, Year) %>% 
  group_by(Site.ID) %>% 
  summarise(n = n()) %>% filter(n > 4) %>% 
  nrow() #1271: all  #1211: with 4+ years

check <- dt.ozone.warm %>% 
  group_by(Site.ID) %>% 
  summarise(n = n()) %>% 
  arrange(n)

summary(check$n)
```

```{r Zipcodes in x-mile bufferzone of Monitoring Sites}
# remove o3 measures for now to make the dataset smaller
dt.ozone <- dt.ozone.warm %>% 
  select(Site.ID, Year) %>% 
  mutate(psuedo = 100)

# joining zipcodes to monitoring sites
dt.ozone <- dt.ozone %>% 
  inner_join(dt.site.zip, by = c("Site.ID", "Year")) %>% 
  arrange(Zip.Code, Year, Dist)

# for each zipcode, pick the site with shorter distance to zipcode centroeid
dt.site.dist.shorter <- dt.ozone %>% 
  group_by(Zip.Code, Year) %>% 
  filter(Dist == min (Dist)) %>% 
  arrange(Zip.Code, Year) %>% 
  as.data.frame()

# 6-mile bufferzone around monitoring site
dt.ozone.site.zip.bz6 <- dt.site.dist.shorter %>% 
  filter(Dist <= 6) %>% 
  select(Zip.Code, Year, Site.ID, psuedo)

save(dt.ozone.site.zip.bz6, 
     file = here('data', 'processed', 'ozone-site-zip-bz6.RDa'))
write.csv(dt.ozone.site.zip.bz6, 
          file = here('data', 'processed', 'ozone-site-zip-bz6.csv'),
          row.names = F)

# Count number of zipcodes and sites
dt.ozone.site.zip.bz6 %>% distinct(Zip.Code) %>% nrow() #10,903
dt.ozone.site.zip.bz6 %>% distinct(Site.ID) %>% nrow() #1271 > 1224

# ozone-site-zip-bz6.csv was uploaded on NEU Cluster to be merged with CMS data
# It has 1224 sites with 10,903 zipcodes around them
```

```{r Post mergeing with CMS Data}
dt.ozone.site.ndi <- read.csv(here('data', 'processed', 'site_ozone_ndi.csv')) %>% 
  rename(Site.ID = Site_ID) %>% 
  left_join(dt.aqs.sites)
# 1221 out of 1224 sites have population living in their 6-mile bufferzone

summary(dt.ozone.site.ndi$Location.Setting) 
fix(dt.ozone.site.ndi) # changed blanks to 'RURAL'

save(dt.ozone.site.ndi, file = here('data', 'processed', 'ozone-site-ndi.RDa'))
write.csv(dt.ozone.site.ndi, 
          file = here('data', 'processed', 'ozone-site-ndi.csv'),
          row.names = F)

dt.ozone.site.ndi %>% 
  group_by(Location.Setting) %>% 
  summarise(n = n())
# RURAL	522			
# SUBURBAN	493			
# URBAN AND CENTER CITY	206
```

```{r Extending bufferzone to 12- and 24-}
# sites that have population in their 6-mile buffer
# remove o3 measures for now to make the dataset smaller
dt.ozone <- dt.ozone.warm %>% 
  select(Site.ID, Year) %>% 
  mutate(psuedo = 100) %>% 
  inner_join(dt.ozone.site.ndi)

# joining zipcodes to monitoring sites
dt.ozone <- dt.ozone %>% 
  inner_join(dt.site.zip, by = c("Site.ID", "Year")) %>% 
  arrange(Zip.Code, Year, Dist)

# for each zipcode, pick the site with shorter distance to zipcode centroeid
dt.site.dist.shorter <- dt.ozone %>% 
  group_by(Zip.Code, Year) %>% 
  filter(Dist == min (Dist)) %>% 
  arrange(Zip.Code, Year) %>% 
  as.data.frame()

# 12-mile bufferzone around monitoring site
dt.ozone.site.zip.bz12 <- dt.site.dist.shorter %>% 
  filter(Dist <= 12) %>% 
  select(Zip.Code, Year, Site.ID, psuedo)

save(dt.ozone.site.zip.bz12, 
     file = here('data', 'processed', 'ozone-site-zip-bz12.RDa'))
write.csv(dt.ozone.site.zip.bz12, 
          file = here('data', 'processed', 'ozone-site-zip-bz12.csv'),
          row.names = F)

# Count number of zipcodes and sites
dt.ozone.site.zip.bz12 %>% distinct(Zip.Code) %>% nrow() #18,780 > 18681
dt.ozone.site.zip.bz12 %>% distinct(Site.ID) %>% nrow() #1258 > 1221

# 24-mile bufferzone around monitoring site
dt.ozone.site.zip.bz24 <- dt.site.dist.shorter %>% 
  filter(Dist <= 24) %>% 
  select(Zip.Code, Year, Site.ID, psuedo)

save(dt.ozone.site.zip.bz24, 
     file = here('data', 'processed', 'ozone-site-zip-bz24.RDa'))
write.csv(dt.ozone.site.zip.bz24, 
          file = here('data', 'processed', 'ozone-site-zip-bz24.csv'),
          row.names = F)

# Count number of zipcodes and sites
dt.ozone.site.zip.bz24 %>% distinct(Zip.Code) %>% nrow() #28,029 > 27794
dt.ozone.site.zip.bz24 %>% distinct(Site.ID) %>% nrow() #1268 > 1221
```


```{r - Adding yearly pm and no2 data to warm season ozone data}
# all zipcodes in 6-mile bufferzone of each site each year
dt.ozone.site.all.zip.bz6  <- dt.ozone.warm %>% 
  inner_join(dt.ozone.site.ndi) %>% 
  inner_join(dt.site.zip) %>% 
  arrange(Site.ID, Year, Dist) %>% 
  filter(Dist <= 6) %>% 
  select(-Zip.Type, -Dist)

write.csv(dt.ozone.site.all.zip.bz6, 
          file = here('data', 'processed', 'ozone-site-all-zip-bz6.csv'), 
          row.names = F)

# all zipcodes in 12-mile bufferzone of each site each year
dt.ozone.site.all.zip.bz12  <- dt.ozone.warm %>% 
  inner_join(dt.ozone.site.ndi) %>% 
  inner_join(dt.site.zip) %>% 
  arrange(Site.ID, Year, Dist) %>% 
  filter(Dist <= 12) %>% 
  select(-Zip.Type, -Dist)

write.csv(dt.ozone.site.all.zip.bz12, 
          file = here('data', 'processed', 'ozone-site-all-zip-bz12.csv'), 
          row.names = F)

# all zipcodes in 24-mile bufferzone of each site each year
dt.ozone.site.all.zip.bz24  <- dt.ozone.warm %>% 
  inner_join(dt.ozone.site.ndi) %>% 
  inner_join(dt.site.zip) %>% 
  arrange(Site.ID, Year, Dist) %>% 
  filter(Dist <= 24) %>% 
  select(-Zip.Type, -Dist)

write.csv(dt.ozone.site.all.zip.bz24, 
          file = here('data', 'processed', 'ozone-site-all-zip-bz24.csv'), 
          row.names = F)

# ozone-site-all-zip-bz.csv were uploaded on NEU Cluster to be merged with ...
# ... -1yr-mvavg zipcode level PM data.


# 1yr-mvavg PM value for each site based on zipcodes in x-mile value
dt.pm.ozone.bz6 <- read.csv(
  here('data', 'processed','pm_ozone_bz6.csv')) %>% 
  rename(Site.ID = Site_ID,
         Month = month,
         PM = PM_1yr)
save(dt.pm.ozone.bz6, 
     file = here('data', 'processed', 'pm-ozone-bz6.RDa'))

dt.pm.ozone.bz12 <- read.csv(
  here('data', 'processed','pm_ozone_bz12.csv')) %>% 
  rename(Site.ID = Site_ID,
         Month = month,
         PM = PM_1yr)
save(dt.pm.ozone.bz12, 
     file = here('data', 'processed', 'pm-ozone-bz12.RDa'))

dt.pm.ozone.bz24 <- read.csv(
  here('data', 'processed','pm_ozone_bz24.csv')) %>% 
  rename(Site.ID = Site_ID,
         Month = month,
         PM = PM_1yr)
save(dt.pm.ozone.bz24, 
     file = here('data', 'processed', 'pm-ozone-bz24.RDa'))


# 1yr-mvavg NO2 value for each site based on zipcodes in x-mile value
dt.no2.ozone.bz6 <- read.csv(
  here('data', 'processed','no2_ozone_bz6.csv')) %>% 
  rename(Site.ID = Site_ID,
         Month = month,
         NO2 = NO2_1yr)
save(dt.no2.ozone.bz6, 
     file = here('data', 'processed', 'no2-ozone-bz6.RDa'))

dt.no2.ozone.bz12 <- read.csv(
  here('data', 'processed','no2_ozone_bz12.csv')) %>% 
  rename(Site.ID = Site_ID,
         Month = month,
         NO2 = NO2_1yr)
save(dt.no2.ozone.bz12, 
     file = here('data', 'processed', 'no2-ozone-bz12.RDa'))

dt.no2.ozone.bz24 <- read.csv(
  here('data', 'processed','no2_ozone_bz24.csv')) %>% 
  rename(Site.ID = Site_ID,
         Month = month,
         NO2 = NO2_1yr)
save(dt.no2.ozone.bz24, 
     file = here('data', 'processed', 'no2-ozone-bz24.RDa'))
```

